algorithm:
  activation_fn: Tanh
  use_sde: false
  use_expln: false
  feature_extractor:
    share_feature_extractor: true
    grid_encoder:
      embedding_dim: 32
      type: cnn
      output_dim: 32
      conv_layers:
      - in_channels: ${...embedding_dim}
        out_channels: 32
        kernel_size: 3
        stride: 1
        padding: 0
    agent_id_encoder:
      type: cnn
      output_dim: 32
      conv_layers:
      - in_channels: 1
        out_channels: 32
        kernel_size: 3
        stride: 1
        padding: 0
    items_encoder:
      embedding_dim: 8
      layers:
      - 64
      - 32
  lstm:
    enable_critic_lstm: false
    shared_lstm: false
    lstm_hidden_size: 256
    n_lstm_layers: 1
  mlp:
    policy_net:
      lstm_output_to_latent_features:
      - 128
      - 64
      - 32
    value_net:
      lstm_output_to_latent_features:
      - 128
      - 64
      - 32
  training:
    num_env_steps_for_each_gradient_update: 256
    num_epochs_optimizing_surrogate_loss: 10
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_vf: null
    normalize_advantage: true
    ent_coef: 0.0
    vf_coef: 0.5
    max_grad_norm: 0.5
    target_kl: null
  testing:
    max_episode_steps: 25
    n_eval_episodes: 100
environment:
  number_of_envs_to_run_parallelly: 1
hyperparameters:
  training:
    discount_factor: 0.99
    learning_rate: 1.0e-05
    max_episode_steps: 40
    total_num_steps: 100000.0
    batch_size: 64
    num_env_steps_for_each_gradient_update: 256
    num_epochs_optimizing_surrogate_loss: 10
    gae_lambda: 0.95
    clip_range: 0.2
    clip_range_vf: null
    normalize_advantage: true
    ent_coef: 0.0
    vf_coef: 0.5
    max_grad_norm: 0.5
    target_kl: null
logging:
  training:
    log_episode_interval: 2
    stats_episode_window_size: 100
  testing:
    video:
      record_step_interval: 1
      length: 25
      fps: 4
seed: 0
gridverse_env: gv_keydoor.9x9.yaml
