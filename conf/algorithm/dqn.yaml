policy_net:
  hidden_layers: [ 128, 64, 32 ]

replay_buffer_memory: 1e4

training:
  exploration_initial_eps: 0.8
  exploration_final_eps: 0.05
  target_update_interval: 500
  learning_starts: 100
  train_freq: 5
  gradient_steps: 2

testing:
  max_episode_steps: 25
  n_eval_episodes: 100
