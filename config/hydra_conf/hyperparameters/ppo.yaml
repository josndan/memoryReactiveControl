training:
  learning_rate: 1e-3
  gamma: 0.99

  max_rollout_len: 64
  train_batch_size_per_learner: 1024 # timesteps
  num_train_loop: 1

  num_epochs: 8
  minibatch_size: 128 # timesteps
  shuffle_batch_per_epoch: false

  grad_clip: 0.5
  grad_clip_by: 'norm'

  use_critic: true
  use_gae: true
  lambda_: 0.95

  use_kl_loss: false
  kl_coeff: 0.01
  kl_target: 0.01

  vf_loss_coeff: 0.5
  entropy_coeff: 0.001

  clip_param: 0.2
  vf_clip_param: null

