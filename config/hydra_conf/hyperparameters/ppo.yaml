training:
  learning_rate: 5e-4
  gamma: 0.9

  max_rollout_len: 40
  train_batch_size_per_learner: 1024 # timesteps
  num_train_loop: 300

  num_epochs: 10
  minibatch_size: 128 # timesteps
  shuffle_batch_per_epoch: false

  grad_clip: 0.5
  grad_clip_by: 'norm'

  use_critic: true
  use_gae: true
  lambda_: 0.95

  use_kl_loss: false
  kl_coeff: 0.01
  kl_target: 0.01

  vf_loss_coeff: 0.5
  entropy_coeff: 0.03

  clip_param: 0.2
  vf_clip_param: null

