{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:25.136144Z",
     "start_time": "2024-12-02T02:52:23.542419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from torchvision import transforms\n",
    "\n",
    "from gridverse_torch_featureextractors.gridversefeatureextractor import GridVerseFeatureExtractor\n",
    "from gridverse_utils.custom_gridverse_env import register_custom_functions\n",
    "from gridverse_utils.gridversemaker import WorldMaker\n",
    "import tree\n",
    "import numpy as np\n",
    "\n",
    "register_custom_functions()"
   ],
   "id": "78add2af9010fb25",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:26.172605Z",
     "start_time": "2024-12-02T02:52:26.169978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import wandb\n",
    "# \n",
    "# wandb.init(project=\"self-supervised-memory-reactive\")"
   ],
   "id": "28641179dc703a40",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:26.509469Z",
     "start_time": "2024-12-02T02:52:26.428892Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"./config/hydra_conf\", version_base=None)\n",
    "cfg = compose(config_name=\"config\")"
   ],
   "id": "498dff2dce7b38b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:28.456647Z",
     "start_time": "2024-12-02T02:52:28.453772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def numpy_dict_to_tensor(data):\n",
    "    return {k: torch.as_tensor(v) for k, v in data.items()}\n"
   ],
   "id": "69cde4818788e311",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:28.770716Z",
     "start_time": "2024-12-02T02:52:28.767331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gym_gridverse.action import Action\n",
    "\n",
    "\n",
    "def collect_episodes(env, num_episodes, max_step_len):\n",
    "    episodes = []\n",
    "    returns = []\n",
    "    last_num_episodes = 0\n",
    "\n",
    "    while len(episodes) < num_episodes:\n",
    "        episode = [numpy_dict_to_tensor(env.reset()[0])]\n",
    "        epi_return = 0\n",
    "\n",
    "        for i in range(max_step_len - 1):\n",
    "            #random action\n",
    "            action = world.action_space.sample()\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            # obs = numpy_dict_to_tensor(obs)\n",
    "            episode.append(obs)\n",
    "            epi_return += reward\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        if terminated and not truncated:\n",
    "            # repeat last observation so that all episodes have max_step_len\n",
    "            last_obs = episode[-1]\n",
    "            while len(episode) < max_step_len:\n",
    "                episode.append(last_obs)\n",
    "\n",
    "            episode = tree.map_structure(lambda *steps_: np.stack(steps_, axis=0), *episode)\n",
    "\n",
    "            episodes.append(episode)\n",
    "            # Assumes that positive return means agent reached good exit otherwise it reached bad exit\n",
    "            # label 1 means good exit, 0 means bad exit\n",
    "            returns.append(1.0 if epi_return > 0 else 0.0)\n",
    "\n",
    "        if len(episodes) % 100 == 0 and len(episodes) > last_num_episodes:\n",
    "            print(f\"\\tCollected{len(episodes)}\")\n",
    "            last_num_episodes = len(episodes)\n",
    "\n",
    "    episodes = tree.map_structure(lambda *episodes_: np.stack(episodes_, axis=0), *episodes)\n",
    "    returns = np.stack(returns, axis=0)\n",
    "    return episodes, returns\n"
   ],
   "id": "89ac78954dc972f9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:29.165631Z",
     "start_time": "2024-12-02T02:52:29.163908Z"
    }
   },
   "cell_type": "code",
   "source": "# episodes = tree.map_structure(lambda *episodes_: torch.stack(episodes_, dim=0), *episodes)",
   "id": "c0d0bc1f9285a041",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:29.506846Z",
     "start_time": "2024-12-02T02:52:29.499514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gridverse_torch_featureextractors.stacked.transformerencoder import generate_square_subsequent_mask\n",
    "from torch.nn import TransformerEncoderLayer, TransformerEncoder\n",
    "\n",
    "\n",
    "class ReturnPredictorFromSequence(nn.modules.Module):\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, config: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gridverse_feature_extractor = GridVerseFeatureExtractor(observation_space, config.encoder)\n",
    "        self.feature_dim = config.encoder.grid_encoder.output_dim + \\\n",
    "                           config.encoder.agent_id_encoder.output_dim + \\\n",
    "                           config.encoder.items_encoder.layers[-1]\n",
    "        self.rnn_hidden_dim = config.lstm_cell_size\n",
    "        self.rnn = nn.LSTM(input_size=self.feature_dim, hidden_size=self.rnn_hidden_dim, batch_first=True)\n",
    "\n",
    "        # encoder_layer = TransformerEncoderLayer(d_model=self.feature_dim, nhead=8, batch_first=True)\n",
    "        # self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=6)\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.rnn_hidden_dim, out_features=128),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=32, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, episodes):\n",
    "        # reversing the episode so RNN process steps from the end\n",
    "        # (num_batch/ num_episode, num_timesteps,..)\n",
    "        episodes = tree.map_structure(lambda dict_val: torch.flip(dict_val, dims=[1]), episodes)\n",
    "        num_batch, num_steps, *_ = next(iter(episodes.values())).size()\n",
    "\n",
    "        def combine_batch_and_time_dim(tensor):\n",
    "            _, _, *feature_dims = tensor.size()\n",
    "            return tensor.reshape(-1, *feature_dims)\n",
    "\n",
    "        episodes = tree.map_structure(combine_batch_and_time_dim, episodes)\n",
    "\n",
    "        features = self.gridverse_feature_extractor(episodes)\n",
    "        _, *feature_dims = features.size()\n",
    "\n",
    "        # batch_size, num_steps, feature_dim\n",
    "        features = features.reshape(num_batch, num_steps, *feature_dims)\n",
    "\n",
    "        # mask = generate_square_subsequent_mask(num_steps)\n",
    "        # transformer_output = self.transformer_encoder(features, mask=mask)\n",
    "        # \n",
    "        # aggregated_output = transformer_output[:, -1, :]  # Take the last timestep\n",
    "        out, (rnn_h_n, c_n) = self.rnn(features)\n",
    "\n",
    "        outputs = self.linear(out)\n",
    "\n",
    "        return outputs"
   ],
   "id": "87570d690fa385a2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:29.821200Z",
     "start_time": "2024-12-02T02:52:29.815616Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReturnPredictorFromMemoryAndReactiveObs(nn.modules.Module):\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, config: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gridverse_feature_extractor = GridVerseFeatureExtractor(observation_space, config.encoder)\n",
    "        self.feature_dim = config.encoder.grid_encoder.output_dim + \\\n",
    "                           config.encoder.agent_id_encoder.output_dim + \\\n",
    "                           config.encoder.items_encoder.layers[-1]\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=2 * self.feature_dim, out_features=128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, memory_reactive_obs):\n",
    "        #(N,2,grid_verse_dim..)\n",
    "        num_batch, num_obs, *_ = next(iter(memory_reactive_obs.values())).size()\n",
    "\n",
    "        def combine_batch_and_time_dim(tensor):\n",
    "            _, _, *feature_dims = tensor.size()\n",
    "            return tensor.reshape(-1, *feature_dims)\n",
    "\n",
    "        memory_reactive_obs = tree.map_structure(combine_batch_and_time_dim, memory_reactive_obs)\n",
    "\n",
    "        features = self.gridverse_feature_extractor(memory_reactive_obs)\n",
    "\n",
    "        _, *feature_dims = features.size()\n",
    "\n",
    "        # batch_size, num_steps, feature_dim\n",
    "        features = features.reshape(num_batch, num_obs, *feature_dims)\n",
    "\n",
    "        # concatenating the features\n",
    "        features = features.reshape(num_batch, -1)\n",
    "\n",
    "        outputs = self.linear(features)\n",
    "        return outputs\n",
    "\n"
   ],
   "id": "ad5170e9553606c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:04:25.266368Z",
     "start_time": "2024-12-02T03:04:25.254925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# env param\n",
    "max_step_len = 50\n",
    "num_train_episodes = 5000\n",
    "num_valid_episodes = 1000\n",
    "num_test_episodes = 1000\n",
    "env_name = 'gv_memory.5x5'\n",
    "worldMaker = WorldMaker(f'./config/gridverse_conf/{env_name}.yaml')\n",
    "world = worldMaker.make_env()\n",
    "\n",
    "# hyper param\n",
    "batch_size = 128  # this is number of episodes when using sequence and num time steps when not using sequence\n",
    "num_epochs = 1\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# params\n",
    "aggregate_stats_every_n_batch = 50\n",
    "model_path = f'{env_name}.self_supervised_memory.pt'\n"
   ],
   "id": "c9a16c5d01793117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gridverse using YAML in ./config/gridverse_conf/gv_memory.5x5.yaml\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:30.600090Z",
     "start_time": "2024-12-02T02:52:30.595722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "from gym_gridverse.grid_object import Beacon\n",
    "\n",
    "world.reset()\n",
    "beacon_index = None\n",
    "state = world.outer_env.inner_env.state.grid\n",
    "for i in range(state.shape.width):\n",
    "    for j in range(state.shape.width):\n",
    "        if isinstance(state.objects[i][j], Beacon):\n",
    "            beacon_index = state.objects[i][j].type_index()\n",
    "            break"
   ],
   "id": "7e4e3c78571633e0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:30.962667Z",
     "start_time": "2024-12-02T02:52:30.959183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(self, episodes: dict, labels: np.array, transform=None, get_suffix_sequence=False,\n",
    "                 filter_by_beacon=False):\n",
    "        self.episodes = episodes\n",
    "        self.num_episodes, self.rollout_len, *_ = episodes['grid'].shape\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.get_suffix_sequence = get_suffix_sequence\n",
    "        self.filter_by_beacon = filter_by_beacon\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_episodes * (self.rollout_len - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        (episode_index, rollout_index) = idx\n",
    "\n",
    "        if not self.get_suffix_sequence:\n",
    "            # this is memory and reactive observation pair\n",
    "            rollout_sub_seq = tree.map_structure(\n",
    "                lambda episodes_value: np.stack(\n",
    "                    [episodes_value[episode_index, rollout_index], episodes_value[episode_index, self.rollout_len - 1]],\n",
    "                    axis=0),\n",
    "                self.episodes)\n",
    "        else:\n",
    "            rollout_sub_seq = tree.map_structure(\n",
    "                lambda episodes_value: episodes_value[episode_index, rollout_index:],\n",
    "                self.episodes)\n",
    "\n",
    "        sample = self.transform(rollout_sub_seq)\n",
    "\n",
    "        if self.filter_by_beacon:\n",
    "            if beacon_index in sample['grid'][..., 0]:\n",
    "                label = self.labels[episode_index]\n",
    "            else:\n",
    "                # if there's no beacon 0.5\n",
    "                label = 0.5\n",
    "        else:\n",
    "            label = self.labels[episode_index]\n",
    "\n",
    "        return sample, label"
   ],
   "id": "943b6df29aa44d2f",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:32.132417Z",
     "start_time": "2024-12-02T02:52:32.127705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "\n",
    "class EpisodeAndSequenceIndexBatchSampler(Sampler[List[int]]):\n",
    "    def __init__(self, num_episodes, rollout_len, batch_size, keep_rollout_index_constant_across_batch=True):\n",
    "        super().__init__()\n",
    "        self.num_episodes = num_episodes\n",
    "        self.rollout_len = rollout_len\n",
    "        self.batch_size = batch_size\n",
    "        self.keep_rollout_index_constant_across_batch = keep_rollout_index_constant_across_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_episodes * (self.rollout_len - 1)\n",
    "\n",
    "    def __iter__(self):\n",
    "        def get_idx(num_batch, batch_size):\n",
    "            if self.keep_rollout_index_constant_across_batch:\n",
    "                rollout_idx = np.random.randint(0, self.rollout_len - 1, (num_batch, 1))\n",
    "                rollout_idx = np.broadcast_to(rollout_idx, (num_batch, batch_size))\n",
    "            else:\n",
    "                rollout_idx = np.random.randint(0, self.rollout_len - 1, (num_batch, batch_size))\n",
    "            episode_idx = np.random.randint(0, self.num_episodes, (num_batch, batch_size,))\n",
    "            idx = np.stack([episode_idx, rollout_idx], axis=-1)\n",
    "            return idx\n",
    "\n",
    "        num_batch = len(self) // self.batch_size\n",
    "        idx = get_idx(num_batch, self.batch_size)\n",
    "\n",
    "        for _ in range(len(self) // self.batch_size):\n",
    "            yield from idx.tolist()\n",
    "        remaining = get_idx(1, len(self) % self.batch_size).squeeze()\n",
    "        yield remaining\n",
    "\n"
   ],
   "id": "1f3ce10c99ae045c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:33.141437Z",
     "start_time": "2024-12-02T02:52:33.137899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert dict ndarrays in sample to dict Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return {k: torch.as_tensor(v) for k, v in sample.items()}\n",
    "\n",
    "\n",
    "composed = transforms.Compose([\n",
    "    ToTensor()\n",
    "])"
   ],
   "id": "2d938b470197274b",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T02:52:34.945821Z",
     "start_time": "2024-12-02T02:52:34.941182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collect_and_save_episodes():\n",
    "    print(\"Collecting train episodes...\")\n",
    "    train_episodes, returns = collect_episodes(world, num_train_episodes, max_step_len)\n",
    "    train_dataset = EpisodeDataset(train_episodes, returns, transform=composed, get_suffix_sequence=True,\n",
    "                                   filter_by_beacon=False)\n",
    "    torch.save(train_dataset, f'{env_name}.train_dataset.pt')\n",
    "\n",
    "    print(\"Collecting validation episodes...\")\n",
    "    validation_episodes, returns = collect_episodes(world, num_valid_episodes, max_step_len)\n",
    "    validation_dataset = EpisodeDataset(validation_episodes, returns, transform=composed, get_suffix_sequence=True,\n",
    "                                        filter_by_beacon=False)\n",
    "    torch.save(validation_dataset, f'{env_name}.validation_dataset.pt')\n",
    "\n",
    "    print(\"Collecting test episodes...\")\n",
    "    test_episodes, returns = collect_episodes(world, num_test_episodes, max_step_len)\n",
    "    test_dataset = EpisodeDataset(test_episodes, returns, transform=composed, get_suffix_sequence=True,\n",
    "                                  filter_by_beacon=False)\n",
    "    torch.save(test_dataset, f'{env_name}.test_dataset.pt')\n",
    "\n",
    "# collect_and_save_episodes()"
   ],
   "id": "e69ca27143e50926",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:04:29.966648Z",
     "start_time": "2024-12-02T03:04:29.961028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch._C._profiler import ProfilerActivity\n",
    "\n",
    "\n",
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    with torch.profiler.profile(activities=[ProfilerActivity.CPU],\n",
    "                                record_shapes=True,\n",
    "                                profile_memory=True,\n",
    "                                with_stack=True, ) as prof:\n",
    "        for i, batch in enumerate(train_dataloader):\n",
    "            inputs, labels = batch\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs).squeeze()\n",
    "            # unsqueeze and expand labels for time dim\n",
    "            labels = labels[..., None].expand(*outputs.shape)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            prof.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if i % aggregate_stats_every_n_batch == (aggregate_stats_every_n_batch - 1):\n",
    "                last_loss = running_loss / aggregate_stats_every_n_batch  # loss per batch\n",
    "                print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "                running_loss = 0.\n",
    "\n",
    "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "    return last_loss"
   ],
   "id": "366ca32fdf6ac52e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T03:04:31.308902Z",
     "start_time": "2024-12-02T03:04:30.728779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = torch.load(f'{env_name}.train_dataset.pt')\n",
    "train_sampler = EpisodeAndSequenceIndexBatchSampler(num_train_episodes, max_step_len, batch_size=batch_size,\n",
    "                                                    keep_rollout_index_constant_across_batch=True)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_sampler=train_sampler)\n",
    "\n",
    "validation_dataset = torch.load(f'{env_name}.validation_dataset.pt')\n",
    "validation_sampler = EpisodeAndSequenceIndexBatchSampler(num_valid_episodes, max_step_len, batch_size=batch_size,\n",
    "                                                         keep_rollout_index_constant_across_batch=True)\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_sampler=validation_sampler)\n",
    "\n",
    "model = ReturnPredictorFromSequence(world.observation_space, cfg.algorithm)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epoch_number = 0"
   ],
   "id": "855c0e57f126b976",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7v/7zkq50550235g1kcjw6b9j4h0000gn/T/ipykernel_54303/1838104249.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_dataset = torch.load(f'{env_name}.train_dataset.pt')\n",
      "/var/folders/7v/7zkq50550235g1kcjw6b9j4h0000gn/T/ipykernel_54303/1838104249.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  validation_dataset = torch.load(f'{env_name}.validation_dataset.pt')\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-12-02T03:04:34.117539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "print(\"Starting training...\")\n",
    "best_vloss = float(\"inf\")\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader):\n",
    "            inputs, labels = data\n",
    "\n",
    "            outputs = model(inputs).squeeze()\n",
    "\n",
    "            # unsqueeze and expand labels for time dim\n",
    "            labels = labels[..., None].expand(*outputs.shape)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_vloss += loss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # wandb.log({'train/loss': avg_loss, 'valid/loss': avg_vloss}, epoch_number + 1)\n",
    "    epoch_number += 1\n",
    "    # epoch_number += i\n"
   ],
   "id": "4b3eb128beb7b973",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "EPOCH 1:\n",
      "  batch 50 loss: 0.6936407166607319\n",
      "  batch 100 loss: 0.6926678948316791\n",
      "  batch 150 loss: 0.5647560906545629\n",
      "  batch 200 loss: 0.43778205525324554\n",
      "  batch 250 loss: 0.41061081452039505\n",
      "  batch 300 loss: 0.4143646131538398\n",
      "  batch 350 loss: 0.421618992147714\n",
      "  batch 400 loss: 0.4052708839831194\n",
      "  batch 450 loss: 0.39908213363340833\n",
      "  batch 500 loss: 0.4078004080862766\n",
      "  batch 550 loss: 0.39698186146109987\n",
      "  batch 600 loss: 0.40140254549615917\n",
      "  batch 650 loss: 0.3992457102310621\n",
      "  batch 700 loss: 0.3916446151132194\n",
      "  batch 750 loss: 0.39861348596009444\n",
      "  batch 800 loss: 0.3996219066660499\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = torch.load(f'{env_name}.test_dataset.pt')\n",
    "test_sampler = EpisodeAndSequenceIndexBatchSampler(num_test_episodes, max_step_len, batch_size=batch_size,\n",
    "                                                   keep_rollout_index_constant_across_batch=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_sampler=test_sampler)\n",
    "model = ReturnPredictorFromMemoryAndReactiveObs(world.observation_space, cfg.algorithm)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ],
   "id": "78ff33cfe181a127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = []",
   "id": "4805814d389d384d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        inputs, labels = batch\n",
    "\n",
    "        # # removing data items with 0.5 label\n",
    "        # inputs = tree.map_structure(\n",
    "        #     lambda _inputs: _inputs[labels != 0.5], inputs)\n",
    "        # \n",
    "        # labels = labels[labels != 0.5]\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # unsqueeze and expand labels for time dim\n",
    "        labels = labels[..., None].expand(*outputs.shape)\n",
    "\n",
    "        # Get the model's prediction after it has seen the first step.\n",
    "        # The test dataset definitely contains the Memory observation.\n",
    "        outputs = torch.sigmoid(outputs.squeeze())\n",
    "        res.extend(outputs.cpu().numpy())\n",
    "\n",
    "        total_correct += (labels * outputs + (1 - labels) * (1 - outputs)).sum().item()\n",
    "        total_samples += outputs.numel()\n",
    "\n",
    "    acc = total_correct / total_samples\n",
    "    # wandb.log({\"test/one_or_zero_class_acc\": one_or_zero_class_acc})\n",
    "    print(f'accuracy: {acc * 100:0.2f} %')\n",
    "    print(total_samples)\n"
   ],
   "id": "2f0d0446e132f61e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = np.array(res)",
   "id": "6d398f4ab9250ec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res.shape",
   "id": "9025130ed2cbfd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "d8682a39e844858f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hist, bin_edges = np.histogram(res, bins=100, range=(0, 1))",
   "id": "5e7e94bde270550c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), align=\"edge\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frequency Distribution\")\n",
    "plt.show()"
   ],
   "id": "2d03bea75eb7d63b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# wandb.finish()",
   "id": "8b359aafdc66cea3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rollout_len = 50\n",
    "num_episodes = 5000"
   ],
   "id": "d924de653e071ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_learnable_memory_reactive_pair_per_episode = 1  # This could be more or less than this. \n",
    "num_memory_reactive_pair_per_episode = rollout_len - 1"
   ],
   "id": "ce7400f3b769fe1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tot_learnable_pair = num_learnable_memory_reactive_pair_per_episode * num_episodes\n",
    "tot_pair = num_memory_reactive_pair_per_episode * num_episodes"
   ],
   "id": "4ea0eeb4f4fe1007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tot_learnable_pair, tot_pair, tot_learnable_pair / tot_pair",
   "id": "15b4d4b2a96b5577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise = 1 - tot_learnable_pair / tot_pair\n",
    "f'noise: {noise * 100:0.2f} %'"
   ],
   "id": "a2f9553d33744092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "384c5695801f1515",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
