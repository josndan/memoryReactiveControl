{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:18.494641Z",
     "start_time": "2024-12-01T20:25:17.012828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from torchvision import transforms\n",
    "\n",
    "from gridverse_torch_featureextractors.gridversefeatureextractor import GridVerseFeatureExtractor\n",
    "from gridverse_utils.custom_gridverse_env import register_custom_functions\n",
    "from gridverse_utils.gridversemaker import WorldMaker\n",
    "import tree\n",
    "import numpy as np\n",
    "\n",
    "register_custom_functions()"
   ],
   "id": "78add2af9010fb25",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:18.998668Z",
     "start_time": "2024-12-01T20:25:18.995770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import wandb\n",
    "# \n",
    "# wandb.init(project=\"self-supervised-memory-reactive\")"
   ],
   "id": "28641179dc703a40",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:19.330611Z",
     "start_time": "2024-12-01T20:25:19.244032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"./config/hydra_conf\", version_base=None)\n",
    "cfg = compose(config_name=\"config\")"
   ],
   "id": "498dff2dce7b38b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:19.654717Z",
     "start_time": "2024-12-01T20:25:19.652136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def numpy_dict_to_tensor(data):\n",
    "    return {k: torch.as_tensor(v) for k, v in data.items()}\n"
   ],
   "id": "69cde4818788e311",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:20.018042Z",
     "start_time": "2024-12-01T20:25:20.014520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gym_gridverse.action import Action\n",
    "\n",
    "\n",
    "def collect_episodes(env, num_episodes, max_step_len, test=False):\n",
    "    episodes = []\n",
    "    returns = []\n",
    "    last_num_episodes = 0\n",
    "\n",
    "    while len(episodes) < num_episodes:\n",
    "        episode = [numpy_dict_to_tensor(world.reset()[0])]\n",
    "        epi_return = 0\n",
    "\n",
    "        for i in range(max_step_len - 1):\n",
    "            #random action\n",
    "            if test and i < 4:\n",
    "                # Cannot reach exit by turning but definitely sees beacon in 5x5 grid\n",
    "                action = Action.TURN_RIGHT.value\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "            else:\n",
    "                action = world.action_space.sample()\n",
    "                obs, reward, terminated, truncated, info = env.step(action)\n",
    "            # obs = numpy_dict_to_tensor(obs)\n",
    "            episode.append(obs)\n",
    "            epi_return += reward\n",
    "\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        if terminated and not truncated:\n",
    "            # repeat last observation so that all episodes have max_step_len\n",
    "            last_obs = episode[-1]\n",
    "            while len(episode) < max_step_len:\n",
    "                episode.append(last_obs)\n",
    "\n",
    "            episode = tree.map_structure(lambda *steps_: np.stack(steps_, axis=0), *episode)\n",
    "\n",
    "            episodes.append(episode)\n",
    "            # Assumes that positive return means agent reached good exit otherwise it reached bad exit\n",
    "            # label 1 means good exit, 0 means bad exit\n",
    "            returns.append(1.0 if epi_return > 0 else 0.0)\n",
    "\n",
    "        if len(episodes) % 100 == 0 and len(episodes) > last_num_episodes:\n",
    "            print(f\"\\tCollected{len(episodes)}\")\n",
    "            last_num_episodes = len(episodes)\n",
    "\n",
    "    episodes = tree.map_structure(lambda *episodes_: np.stack(episodes_, axis=0), *episodes)\n",
    "    returns = np.stack(returns, axis=0)\n",
    "    return episodes, returns\n"
   ],
   "id": "89ac78954dc972f9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:20.554581Z",
     "start_time": "2024-12-01T20:25:20.553085Z"
    }
   },
   "cell_type": "code",
   "source": "# episodes = tree.map_structure(lambda *episodes_: torch.stack(episodes_, dim=0), *episodes)",
   "id": "c0d0bc1f9285a041",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:20.846021Z",
     "start_time": "2024-12-01T20:25:20.838084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gridverse_torch_featureextractors.stacked.transformerencoder import generate_square_subsequent_mask\n",
    "from torch.nn import TransformerEncoderLayer, TransformerEncoder\n",
    "\n",
    "\n",
    "class ReturnPredictorFromSequence(nn.modules.Module):\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, config: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gridverse_feature_extractor = GridVerseFeatureExtractor(observation_space, config.encoder)\n",
    "        self.feature_dim = config.encoder.grid_encoder.output_dim + \\\n",
    "                           config.encoder.agent_id_encoder.output_dim + \\\n",
    "                           config.encoder.items_encoder.layers[-1]\n",
    "        hidden_dim = config.lstm_cell_size\n",
    "        self.rnn = nn.LSTM(input_size=self.feature_dim, hidden_size=hidden_dim, batch_first=True)\n",
    "\n",
    "        # encoder_layer = TransformerEncoderLayer(d_model=self.feature_dim, nhead=8, batch_first=True)\n",
    "        # self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=6)\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=self.feature_dim, out_features=1),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(in_features=128, out_features=64),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(in_features=64, out_features=32),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.Linear(in_features=32, out_features=1)\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, episodes):\n",
    "        # reversing the episode so RNN process steps from the end\n",
    "        # (num_batch/ num_episode, num_timesteps,..)\n",
    "        episodes = tree.map_structure(lambda dict_val: torch.flip(dict_val, dims=[1]), episodes)\n",
    "        num_batch, num_steps, *_ = next(iter(episodes.values())).size()\n",
    "\n",
    "        def combine_batch_and_time_dim(tensor):\n",
    "            _, _, *feature_dims = tensor.size()\n",
    "            return tensor.reshape(-1, *feature_dims)\n",
    "\n",
    "        episodes = tree.map_structure(combine_batch_and_time_dim, episodes)\n",
    "\n",
    "        features = self.gridverse_feature_extractor(episodes)\n",
    "        _, *feature_dims = features.size()\n",
    "\n",
    "        # batch_size, num_steps, feature_dim\n",
    "        features = features.reshape(num_batch, num_steps, *feature_dims)\n",
    "\n",
    "        mask = generate_square_subsequent_mask(num_steps)\n",
    "        transformer_output = self.transformer_encoder(features, mask=mask)\n",
    "\n",
    "        aggregated_output = transformer_output[:, -1, :]  # Take the last timestep\n",
    "\n",
    "        # out, (rnn_h_n, c_n) = self.rnn(features)\n",
    "        # rnn_h_n = rnn_h_n.squeeze()\n",
    "\n",
    "        outputs = self.linear(aggregated_output)\n",
    "\n",
    "        return outputs\n",
    "\n"
   ],
   "id": "87570d690fa385a2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:21.359989Z",
     "start_time": "2024-12-01T20:25:21.356791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ReturnPredictorFromMemoryAndReactiveObs(nn.modules.Module):\n",
    "\n",
    "    def __init__(self, observation_space: gym.spaces.Dict, config: dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.gridverse_feature_extractor = GridVerseFeatureExtractor(observation_space, config.encoder)\n",
    "        self.feature_dim = config.encoder.grid_encoder.output_dim + \\\n",
    "                           config.encoder.agent_id_encoder.output_dim + \\\n",
    "                           config.encoder.items_encoder.layers[-1]\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(in_features=2 * self.feature_dim, out_features=128),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=128, out_features=64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(in_features=32, out_features=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, memory_reactive_obs):\n",
    "        #(N,2,grid_verse_dim)\n",
    "        num_batch, num_obs, *_ = next(iter(memory_reactive_obs.values())).size()\n",
    "\n",
    "        def combine_batch_and_time_dim(tensor):\n",
    "            _, _, *feature_dims = tensor.size()\n",
    "            return tensor.reshape(-1, *feature_dims)\n",
    "\n",
    "        memory_reactive_obs = tree.map_structure(combine_batch_and_time_dim, memory_reactive_obs)\n",
    "\n",
    "        features = self.gridverse_feature_extractor(memory_reactive_obs)\n",
    "\n",
    "        _, *feature_dims = features.size()\n",
    "\n",
    "        # batch_size, num_steps, feature_dim\n",
    "        features = features.reshape(num_batch, num_obs, *feature_dims)\n",
    "        features = features.reshape(num_batch, -1)\n",
    "\n",
    "        outputs = self.linear(features)\n",
    "        return outputs\n",
    "\n"
   ],
   "id": "ad5170e9553606c3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:21.871249Z",
     "start_time": "2024-12-01T20:25:21.868629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(self, episodes: dict, labels: np.array, transform=None):\n",
    "        self.episodes = episodes\n",
    "        self.num_episodes, self.rollout_len, *_ = episodes['grid'].shape\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_episodes * self.rollout_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        episode_index = idx // self.rollout_len\n",
    "        rollout_index = idx % self.rollout_len\n",
    "\n",
    "        memory_step_and_reactive_step = tree.map_structure(\n",
    "            lambda episodes_value: np.stack(\n",
    "                [episodes_value[episode_index, rollout_index], episodes_value[episode_index, self.rollout_len - 1]],\n",
    "                axis=0),\n",
    "            self.episodes)\n",
    "        sample = self.transform(memory_step_and_reactive_step)\n",
    "        label = self.labels[episode_index]\n",
    "        return sample, label"
   ],
   "id": "7be22132511a4965",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:23.256158Z",
     "start_time": "2024-12-01T20:25:23.253763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def custom_dataloader_collate(batch):\n",
    "#     combined_dict = {}\n",
    "#     samples, labels = zip(*batch)\n",
    "#     for key in samples[0].keys():\n",
    "#         combined_dict[key] = torch.stack([sample[key] for sample in samples])\n",
    "#     return combined_dict, labels"
   ],
   "id": "7c8b7db50fcafdc3",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:23.678986Z",
     "start_time": "2024-12-01T20:25:23.671060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# env param\n",
    "max_step_len = 50\n",
    "num_train_episodes = 5000\n",
    "num_valid_episodes = 1000\n",
    "num_test_episodes = 1000\n",
    "env_name = 'gv_memory_no_beacon.5x5'\n",
    "worldMaker = WorldMaker(f'./config/gridverse_conf/{env_name}.yaml')\n",
    "world = worldMaker.make_env()\n",
    "\n",
    "# hyper param\n",
    "batch_size = 128  # this is number of episodes when using sequence and num time steps when not using sequence\n",
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "cutoff_mag = 0.1\n",
    "\n",
    "# params\n",
    "aggregate_stats_every_n_batch = 50\n",
    "model_path = f'{env_name}.self_supervised_memory.pt'\n"
   ],
   "id": "c9a16c5d01793117",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading gridverse using YAML in ./config/gridverse_conf/gv_memory_no_beacon.5x5.yaml\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:25:25.370703Z",
     "start_time": "2024-12-01T20:25:25.367649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert dict ndarrays in sample to dict Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        return {k: torch.as_tensor(v) for k, v in sample.items()}\n",
    "\n",
    "\n",
    "composed = transforms.Compose([\n",
    "    ToTensor()\n",
    "])"
   ],
   "id": "2d938b470197274b",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T20:26:47.540767Z",
     "start_time": "2024-12-01T20:25:29.027084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def collect_and_save_episodes():\n",
    "    print(\"Collecting train episodes...\")\n",
    "    train_episodes, returns = collect_episodes(world, num_train_episodes, max_step_len)\n",
    "    train_dataset = EpisodeDataset(train_episodes, returns, transform=composed)\n",
    "    torch.save(train_dataset, f'{env_name}.train_dataset.pt')\n",
    "\n",
    "    print(\"Collecting validation episodes...\")\n",
    "    validation_episodes, returns = collect_episodes(world, num_valid_episodes, max_step_len)\n",
    "    validation_dataset = EpisodeDataset(validation_episodes, returns, transform=composed)\n",
    "    torch.save(validation_dataset, f'{env_name}.validation_dataset.pt')\n",
    "\n",
    "    print(\"Collecting test episodes...\")\n",
    "    test_episodes, returns = collect_episodes(world, num_test_episodes, max_step_len, test=True)\n",
    "    test_dataset = EpisodeDataset(test_episodes, returns, transform=composed)\n",
    "    torch.save(test_dataset, f'{env_name}.test_dataset.pt')\n",
    "\n",
    "\n",
    "collect_and_save_episodes()"
   ],
   "id": "e69ca27143e50926",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting train episodes...\n",
      "\tCollected100\n",
      "\tCollected200\n",
      "\tCollected300\n",
      "\tCollected400\n",
      "\tCollected500\n",
      "\tCollected600\n",
      "\tCollected700\n",
      "\tCollected800\n",
      "\tCollected900\n",
      "\tCollected1000\n",
      "\tCollected1100\n",
      "\tCollected1200\n",
      "\tCollected1300\n",
      "\tCollected1400\n",
      "\tCollected1500\n",
      "\tCollected1600\n",
      "\tCollected1700\n",
      "\tCollected1800\n",
      "\tCollected1900\n",
      "\tCollected2000\n",
      "\tCollected2100\n",
      "\tCollected2200\n",
      "\tCollected2300\n",
      "\tCollected2400\n",
      "\tCollected2500\n",
      "\tCollected2600\n",
      "\tCollected2700\n",
      "\tCollected2800\n",
      "\tCollected2900\n",
      "\tCollected3000\n",
      "\tCollected3100\n",
      "\tCollected3200\n",
      "\tCollected3300\n",
      "\tCollected3400\n",
      "\tCollected3500\n",
      "\tCollected3600\n",
      "\tCollected3700\n",
      "\tCollected3800\n",
      "\tCollected3900\n",
      "\tCollected4000\n",
      "\tCollected4100\n",
      "\tCollected4200\n",
      "\tCollected4300\n",
      "\tCollected4400\n",
      "\tCollected4500\n",
      "\tCollected4600\n",
      "\tCollected4700\n",
      "\tCollected4800\n",
      "\tCollected4900\n",
      "\tCollected5000\n",
      "Collecting validation episodes...\n",
      "\tCollected100\n",
      "\tCollected200\n",
      "\tCollected300\n",
      "\tCollected400\n",
      "\tCollected500\n",
      "\tCollected600\n",
      "\tCollected700\n",
      "\tCollected800\n",
      "\tCollected900\n",
      "\tCollected1000\n",
      "Collecting test episodes...\n",
      "\tCollected100\n",
      "\tCollected200\n",
      "\tCollected300\n",
      "\tCollected400\n",
      "\tCollected500\n",
      "\tCollected600\n",
      "\tCollected700\n",
      "\tCollected800\n",
      "\tCollected900\n",
      "\tCollected1000\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_one_epoch(epoch_index):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, batch in enumerate(train_dataloader):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).squeeze()\n",
    "        # # unsqueeze and expand labels for time dim\n",
    "        # labels = labels[..., None].expand(*outputs.shape)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % aggregate_stats_every_n_batch == (aggregate_stats_every_n_batch - 1):\n",
    "            last_loss = running_loss / aggregate_stats_every_n_batch  # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ],
   "id": "366ca32fdf6ac52e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dataset = torch.load(f'{env_name}.train_dataset.pt')\n",
    "validation_dataset = torch.load(f'{env_name}.validation_dataset.pt')\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, )\n",
    "validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True, )\n",
    "\n",
    "model = ReturnPredictorFromMemoryAndReactiveObs(world.observation_space, cfg.algorithm)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "epoch_number = 0"
   ],
   "id": "855c0e57f126b976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training\n",
    "print(\"Starting training...\")\n",
    "best_vloss = float(\"inf\")\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(validation_dataloader):\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs).squeeze()\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_vloss += loss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    # wandb.log({'train/loss': avg_loss, 'valid/loss': avg_vloss}, epoch_number + 1)\n",
    "    epoch_number += 1\n",
    "    # epoch_number += i\n"
   ],
   "id": "4b3eb128beb7b973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_dataset = torch.load(f'{env_name}.test_dataset.pt')\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, )\n",
    "model = ReturnPredictorFromMemoryAndReactiveObs(world.observation_space, cfg.algorithm)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ],
   "id": "78ff33cfe181a127",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = []",
   "id": "4805814d389d384d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with torch.no_grad():\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, batch in enumerate(test_dataloader):\n",
    "        inputs, labels = batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Get the model's prediction after it has seen the first step.\n",
    "        # The test dataset definitely contains the Memory observation.\n",
    "        outputs = torch.sigmoid(outputs.squeeze())\n",
    "        res.extend(outputs.cpu().numpy())\n",
    "        # note this doesn't calculate the accuracy for the class when the model is unsure.\n",
    "        # this is accuracy for 0,1 class\n",
    "\n",
    "        pos_threshold = 1 - cutoff_mag\n",
    "        neg_threshold = cutoff_mag\n",
    "\n",
    "        outputs[outputs < neg_threshold] = 0\n",
    "        outputs[outputs > pos_threshold] = 1\n",
    "        outputs[torch.logical_and(outputs >= neg_threshold, outputs <= pos_threshold)] = 0.5\n",
    "        total_correct += torch.sum(outputs == labels).item()\n",
    "        total_samples += outputs.numel()\n",
    "    one_or_zero_class_acc = total_correct / total_samples\n",
    "    # wandb.log({\"test/one_or_zero_class_acc\": one_or_zero_class_acc})\n",
    "    print(one_or_zero_class_acc)\n"
   ],
   "id": "2f0d0446e132f61e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res = np.array(res)",
   "id": "6d398f4ab9250ec3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "res.shape",
   "id": "9025130ed2cbfd7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "d8682a39e844858f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "hist, bin_edges = np.histogram(res, bins=100, range=(0, 1))",
   "id": "5e7e94bde270550c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bin_edges[:-1], hist, width=np.diff(bin_edges), align=\"edge\", edgecolor=\"black\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Frequency Distribution\")\n",
    "plt.show()"
   ],
   "id": "2d03bea75eb7d63b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# wandb.finish()",
   "id": "8b359aafdc66cea3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "rollout_len = 50\n",
    "num_episodes = 5000"
   ],
   "id": "d924de653e071ae3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_learnable_memory_reactive_pair_per_episode = 1  # This could be more or less than this. \n",
    "num_memory_reactive_pair_per_episode = rollout_len - 1"
   ],
   "id": "ce7400f3b769fe1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tot_learnable_pair = num_learnable_memory_reactive_pair_per_episode * num_episodes\n",
    "tot_pair = num_memory_reactive_pair_per_episode * num_episodes"
   ],
   "id": "4ea0eeb4f4fe1007",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tot_learnable_pair, tot_pair, tot_learnable_pair / tot_pair",
   "id": "15b4d4b2a96b5577",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise = 1 - tot_learnable_pair / tot_pair\n",
    "f'noise: {noise * 100:0.2f} %'"
   ],
   "id": "a2f9553d33744092",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "384c5695801f1515",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
